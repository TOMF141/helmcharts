## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.defaultStorageClass Global default StorageClass for Persistent Volume(s)
##
global:
  imageRegistry: ""
  ## e.g:
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  defaultStorageClass: ""
  ## Security parameters
  ##
  security:
    ## @param global.security.allowInsecureImages Allows skipping image verification
    allowInsecureImages: false
  ## Compatibility adaptations for Kubernetes platforms
  ##
  compatibility:
    ## Compatibility adaptations for Openshift
    ##
    openshift:
      ## @param global.compatibility.openshift.adaptSecurityContext Adapt the securityContext sections of the deployment to make them compatible with Openshift restricted-v2 SCC: remove runAsUser, runAsGroup and fsGroup and let the platform use their allowed default IDs. Possible values: auto (apply if the detected running cluster is Openshift), force (perform the adaptation always), disabled (do not perform adaptation)
      ##
      adaptSecurityContext: auto
    ## @param global.compatibility.omitEmptySeLinuxOptions If set to true, removes the seLinuxOptions from the securityContexts when it is set to an empty object
    ##
    omitEmptySeLinuxOptions: false

## @section Common parameters
##

## @param kubeVersion Override Kubernetes version
##
kubeVersion: ""
## @param apiVersions Override Kubernetes API versions reported by .Capabilities
##
apiVersions: []
## @param nameOverride String to partially override common.names.name (from v1)
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname (from v1)
##
fullnameOverride: ""
## @param namespaceOverride String to fully override common.names.namespace
##
namespaceOverride: ""
## @param commonLabels Labels to add to all deployed objects
##
commonLabels: {}
## @param commonAnnotations Annotations to add to all deployed objects
##
commonAnnotations: {}
## @param clusterDomain Kubernetes cluster domain name
##
clusterDomain: cluster.local
## @param extraDeploy Array of extra objects to deploy with the release
##
extraDeploy: []
## Diagnostic mode
## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
## @param diagnosticMode.command Command to override all containers in the chart release
## @param diagnosticMode.args Args to override all containers in the chart release
##
diagnosticMode:
  enabled: false
  command:
  - sleep
  args:
  - infinity

## @section Overseerr Parameters
##

## Overseerr Deployment parameters
##
deployment:
  ## Overseerr image (from v1)
  ## @param deployment.image.registry Overseerr image registry
  ## @param deployment.image.repository Overseerr image repository
  ## @skip deployment.image.tag Overseerr image tag (immutable tags are recommended)
  ## @param deployment.image.digest Overseerr image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
  ## @param deployment.image.pullPolicy Overseerr image pull policy
  ## @param deployment.image.pullSecrets Overseerr image pull secrets
  ## @param deployment.image.debug Enable Overseerr image debug mode
  ##
  image:
    registry: lscr.io # From v1
    repository: linuxserver/overseerr # From v1
    tag: "latest" # From v1
    digest: ""
    ## Specify a imagePullPolicy (from v1)
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: Always # From v1
    ## Optionally specify an array of imagePullSecrets. (from v1)
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: [] # From v1
    debug: false
  ## @param deployment.replicaCount Number of overseerr replicas to deploy (from v1)
  ##
  replicaCount: 1 # From v1
  ## @param deployment.containerPorts.http overseerr HTTP container port (from v1 service port)
  ##
  containerPorts:
    http: 5055 # From v1 service port
  ## @param deployment.extraContainerPorts Optionally specify extra list of additional ports for overseerr containers
  ## e.g:
  ## extraContainerPorts:
  ##   - name: myservice
  ##     containerPort: 9090
  ##
  extraContainerPorts: []
  ## Configure extra options for overseerr containers' liveness and readiness probes (adapted from v1)
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param deployment.livenessProbe.enabled Enable livenessProbe on overseerr containers
  ## @param deployment.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param deployment.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param deployment.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param deployment.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param deployment.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true # From v1
    initialDelaySeconds: 30 # From v1
    periodSeconds: 60 # From v1
    timeoutSeconds: 5 # From v1
    failureThreshold: 3 # From v1
    successThreshold: 1 # Default
  ## @param deployment.readinessProbe.enabled Enable readinessProbe on overseerr containers
  ## @param deployment.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param deployment.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param deployment.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param deployment.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param deployment.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true # From v1
    initialDelaySeconds: 15 # From v1
    periodSeconds: 15 # From v1
    timeoutSeconds: 5 # From v1
    failureThreshold: 3 # From v1
    successThreshold: 1 # Default
  ## @param deployment.startupProbe.enabled Enable startupProbe on overseerr containers
  ## @param deployment.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param deployment.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param deployment.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param deployment.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param deployment.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false # Not in v1
    initialDelaySeconds: 30 # Default, but disabled
    periodSeconds: 10 # Default
    timeoutSeconds: 5 # Default
    failureThreshold: 6 # Default (gives 60s total)
    successThreshold: 1 # Default
  ## @param deployment.customLivenessProbe Custom livenessProbe that overrides the default one (adapted from v1)
  ##
  customLivenessProbe:
    httpGet:
      path: /api/v1/status # From v1
      port: http # From v1 (references service port name)
    initialDelaySeconds: 30 # From v1
    periodSeconds: 60 # From v1
    timeoutSeconds: 5 # From v1
    failureThreshold: 3 # From v1
    successThreshold: 1 # Default
  ## @param deployment.customReadinessProbe Custom readinessProbe that overrides the default one (adapted from v1)
  ##
  customReadinessProbe:
    httpGet:
      path: /api/v1/status # From v1
      port: http # From v1 (references service port name)
    initialDelaySeconds: 15 # From v1
    periodSeconds: 15 # From v1
    timeoutSeconds: 5 # From v1
    failureThreshold: 3 # From v1
    successThreshold: 1 # Default
  ## @param deployment.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## overseerr resource requests and limits (from v1)
  ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param deployment.resourcesPreset Set overseerr container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if deployment.resources is set (deployment.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "" # Set to "" as explicit resources are provided
  ## @param deployment.resources Set overseerr container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources:
    # From v1
    limits:
      memory: 512Mi
    requests:
      cpu: 500m
      memory: 258Mi
  ## Configure Pods Security Context (adapted from v1)
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param deployment.podSecurityContext.enabled Enable overseerr pods' Security Context
  ## @param deployment.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy for overseerr pods
  ## @param deployment.podSecurityContext.sysctls Set kernel settings using the sysctl interface for overseerr pods
  ## @param deployment.podSecurityContext.supplementalGroups Set filesystem extra groups for overseerr pods
  ## @param deployment.podSecurityContext.fsGroup Set fsGroup in overseerr pods' Security Context
  ##
  podSecurityContext:
    enabled: true # From v1
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1000 # From v1
  ## Configure Container Security Context (adapted from v1)
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param deployment.containerSecurityContext.enabled Enabled overseerr container' Security Context
  ## @param deployment.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in overseerr container
  ## @param deployment.containerSecurityContext.runAsUser Set runAsUser in overseerr container' Security Context
  ## @param deployment.containerSecurityContext.runAsNonRoot Set runAsNonRoot in overseerr container' Security Context
  ## @param deployment.containerSecurityContext.readOnlyRootFilesystem Set readOnlyRootFilesystem in overseerr container' Security Context
  ## @param deployment.containerSecurityContext.privileged Set privileged in overseerr container' Security Context
  ## @param deployment.containerSecurityContext.allowPrivilegeEscalation Set allowPrivilegeEscalation in overseerr container' Security Context
  ## @param deployment.containerSecurityContext.capabilities.drop List of capabilities to be dropped in overseerr container
  ## @param deployment.containerSecurityContext.seccompProfile.type Set seccomp profile in overseerr container
  ##
  containerSecurityContext:
    enabled: true # From v1
    seLinuxOptions: {}
    runAsUser: 1000 # From v1
    runAsGroup: 1000 # From v1
    runAsNonRoot: false # Set to false based on v1 comment for s6-overlay
    readOnlyRootFilesystem: false # Set to false based on v1 comment
    privileged: false
    allowPrivilegeEscalation: false # From v1
    capabilities:
      drop: [ "ALL" ] # Standard practice
    seccompProfile:
      type: "RuntimeDefault"

  ## @param deployment.command Override default overseerr container command (useful when using custom images)
  ##
  command: []
  ## @param deployment.args Override default overseerr container args (useful when using custom images)
  ##
  args: []
  ## @param deployment.automountServiceAccountToken Mount Service Account token in overseerr pods
  ##
  automountServiceAccountToken: true # Corresponds to serviceAccount.create=true in v1
  ## @param deployment.hostAliases overseerr pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param deployment.deploymentAnnotations Annotations for overseerr deployment (from v1)
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  deploymentAnnotations: {} # From v1
  ## @param deployment.podLabels Extra labels for overseerr pods (from v1)
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {} # From v1
  ## @param deployment.podAnnotations Annotations for overseerr pods (from v1)
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {} # From v1
  ## @param deployment.podAffinityPreset Pod affinity preset. Ignored if `deployment.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param deployment.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `deployment.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft # Default
  ## Node deployment.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param deployment.nodeAffinityPreset.type Node affinity preset type. Ignored if `deployment.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param deployment.nodeAffinityPreset.key Node label key to match. Ignored if `deployment.affinity` is set
    ##
    key: ""
    ## @param deployment.nodeAffinityPreset.values Node label values to match. Ignored if `deployment.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param deployment.affinity Affinity for overseerr pods assignment (from v1)
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `deployment.podAffinityPreset`, `deployment.podAntiAffinityPreset`, and `deployment.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {} # From v1
  ## @param deployment.nodeSelector Node labels for overseerr pods assignment (from v1)
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {} # From v1
  ## @param deployment.tolerations Tolerations for overseerr pods assignment (from v1)
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: [] # From v1
  ## @param deployment.updateStrategy.type overseerr deployment strategy type (from v1)
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  ##
  updateStrategy:
    ## Can be set to RollingUpdate or Recreate
    ##
    type: RollingUpdate # From v1
  ## @param deployment.priorityClassName overseerr pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param deployment.topologySpreadConstraints Topology Spread Constraints for overseerr pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param deployment.schedulerName Name of the k8s scheduler (other than default) for overseerr pods
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param deployment.terminationGracePeriodSeconds Seconds overseerr pods need to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param deployment.lifecycleHooks for overseerr containers to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param deployment.extraEnvVars Array with extra environment variables to add to overseerr containers (from v1 env)
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars:
  # From v1 env
  - name: TZ
    value: Europe/London
  - name: PUID
    value: "1000"
  - name: PGID
    value: "1000"
  - name: UMASK
    value: "002"
  ## @param deployment.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for overseerr containers
  ##
  extraEnvVarsCM: "" # From v1 envFrom
  ## @param deployment.extraEnvVarsSecret Name of existing Secret containing extra env vars for overseerr containers
  ##
  extraEnvVarsSecret: "" # From v1 envFrom
  ## @param deployment.extraVolumes Optionally specify extra list of additional volumes for the overseerr pods
  ##
  extraVolumes: []
  ## @param deployment.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the overseerr containers
  ##
  extraVolumeMounts: []
  ## @param deployment.sidecars Add additional sidecar containers to the overseerr pods
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param deployment.initContainers Add additional init containers to the overseerr pods
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param deployment.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param deployment.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param deployment.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable. Defaults to `1` if both `deployment.pdb.minAvailable` and `deployment.pdb.maxUnavailable` are empty.
  ##
  pdb:
    create: true # Default
    minAvailable: ""
    maxUnavailable: "" # Defaults to 1
  ## Autoscaling configuration
  ## ref: https://kubernetes.io/docs/concepts/workloads/autoscaling/
  ##
  autoscaling:
    ## @param deployment.autoscaling.vpa.enabled Enable VPA for overseerr pods
    ## @param deployment.autoscaling.vpa.annotations Annotations for VPA resource
    ## @param deployment.autoscaling.vpa.controlledResources VPA List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
    ## @param deployment.autoscaling.vpa.maxAllowed VPA Max allowed resources for the pod
    ## @param deployment.autoscaling.vpa.minAllowed VPA Min allowed resources for the pod
    ##
    vpa:
      enabled: false # Default
      annotations: {}
      controlledResources: []
      maxAllowed: {}
      minAllowed: {}
      ## @param deployment.autoscaling.vpa.updatePolicy.updateMode Autoscaling update policy
      ## Specifies whether recommended updates are applied when a Pod is started and whether recommended updates are applied during the life of a Pod
      ## Possible values are "Off", "Initial", "Recreate", and "Auto".
      ##
      updatePolicy:
        updateMode: Auto
    ## @param deployment.autoscaling.hpa.enabled Enable HPA for overseerr pods
    ## @param deployment.autoscaling.hpa.minReplicas Minimum number of replicas
    ## @param deployment.autoscaling.hpa.maxReplicas Maximum number of replicas
    ## @param deployment.autoscaling.hpa.targetCPU Target CPU utilization percentage
    ## @param deployment.autoscaling.hpa.targetMemory Target Memory utilization percentage
    ##
    hpa:
      enabled: false # Default
      minReplicas: ""
      maxReplicas: ""
      targetCPU: ""
      targetMemory: ""

## @section Traffic Exposure Parameters
##

## overseerr service parameters (adapted from v1)
##
service:
  ## @param service.type overseerr service type
  ##
  type: ClusterIP # From v1
  ## @param service.ports.http overseerr service HTTP port
  ##
  ports:
    http: 5055 # From v1
  ## Node ports to expose
  ## @param service.nodePorts.http Node port for HTTP
  ## NOTE: choose port between <30000-32767>
  ##
  nodePorts:
    http: ""
  ## @param service.clusterIP overseerr service Cluster IP
  ## e.g.:
  ## clusterIP: None
  ##
  clusterIP: ""
  ## @param service.loadBalancerIP overseerr service Load Balancer IP
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
  ##
  loadBalancerIP: ""
  ## @param service.loadBalancerSourceRanges overseerr service Load Balancer sources
  ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
  ## e.g:
  ## loadBalancerSourceRanges:
  ##   - 10.10.10.0/24
  ##
  loadBalancerSourceRanges: []
  ## @param service.externalTrafficPolicy overseerr service external traffic policy
  ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
  ##
  externalTrafficPolicy: Cluster # Default
  ## @param service.annotations Additional custom annotations for overseerr service (from v1)
  ##
  annotations: {} # From v1
  ## @param service.extraPorts Extra ports to expose in overseerr service (normally used with the `sidecars` value)
  ##
  extraPorts: []
  ## @param service.sessionAffinity Control where client requests go, to the same pod or round-robin
  ## Values: ClientIP or None
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
  ##
  sessionAffinity: None # Default
  ## @param service.sessionAffinityConfig Additional settings for the sessionAffinity
  ## sessionAffinityConfig:
  ##   clientIP:
  ##     timeoutSeconds: 300
  ##
  sessionAffinityConfig: {}
## Network Policies
## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
##
networkPolicy:
  ## @param networkPolicy.enabled Specifies whether a NetworkPolicy should be created
  ##
  enabled: true # Default
  ## @param networkPolicy.allowExternal Don't require server label for connections
  ## The Policy model to apply. When set to false, only pods with the correct
  ## server label will have network access to the ports server is listening
  ## on. When true, server will accept connections from any source
  ## (with the correct destination port).
  ##
  allowExternal: true # Default
  ## @param networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
  ##
  allowExternalEgress: true # Default
  ## @param networkPolicy.addExternalClientAccess Allow access from pods with client label set to "true". Ignored if `networkPolicy.allowExternal` is true.
  ##
  addExternalClientAccess: true # Default
  ## @param networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
  ## e.g:
  ## extraIngress:
  ##   - ports:
  ##       - port: 1234
  ##     from:
  ##       - podSelector:
  ##           - matchLabels:
  ##               - role: frontend
  ##       - podSelector:
  ##           - matchExpressions:
  ##               - key: role
  ##                 operator: In
  ##                 values:
  ##                   - frontend
  extraIngress: []
  ## @param networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy (ignored if allowExternalEgress=true)
  ## e.g:
  ## extraEgress:
  ##   - ports:
  ##       - port: 1234
  ##     to:
  ##       - podSelector:
  ##           - matchLabels:
  ##               - role: frontend
  ##       - podSelector:
  ##           - matchExpressions:
  ##               - key: role
  ##                 operator: In
  ##                 values:
  ##                   - frontend
  ##
  extraEgress: []
  ## @param networkPolicy.ingressPodMatchLabels [object] Labels to match to allow traffic from other pods. Ignored if `networkPolicy.allowExternal` is true.
  ## e.g:
  ## ingressPodMatchLabels:
  ##   my-client: "true"
  #
  ingressPodMatchLabels: {}
  ## @param networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces. Ignored if `networkPolicy.allowExternal` is true.
  ## @param networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces. Ignored if `networkPolicy.allowExternal` is true.
  ##
  ingressNSMatchLabels: {}
  ingressNSPodMatchLabels: {}
## overseerr ingress parameters (disabled based on v1)
## ref: http://kubernetes.io/docs/concepts/services-networking/ingress/
##
ingress:
  ## @param ingress.enabled Enable ingress record generation for overseerr
  ##
  enabled: false # From v1
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.apiVersion Force Ingress API version (automatically detected if not set)
  ##
  apiVersion: ""
  ## @param ingress.hostname Default host for the ingress record
  ##
  hostname: "overseerr.local" # Default from template, but disabled
  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
  ##
  ingressClassName: "" # From v1
  ## @param ingress.path Default path for the ingress record
  ## NOTE: You may need to set this to '/*' in order to use this with ALB ingress controllers
  ##
  path: / # From v1
  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
  ## Use this parameter to set the required annotations for cert-manager, see
  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
  ## e.g:
  ## annotations:
  ##   kubernetes.io/ingress.class: nginx
  ##   cert-manager.io/cluster-issuer: cluster-issuer-name
  ##
  annotations: {} # From v1
  ## @param ingress.tls Enable TLS configuration for the host defined at `ingress.hostname` parameter
  ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
  ## You can:
  ##   - Use the `ingress.secrets` parameter to create this TLS secret
  ##   - Rely on cert-manager to create it by setting the corresponding annotations
  ##   - Rely on Helm to create self-signed certificates by setting `ingress.selfSigned=true`
  ##
  tls: false # From v1
  ## @param ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
  ##
  selfSigned: false
  ## @param ingress.extraHosts An array with additional hostname(s) to be covered with the ingress record
  ## e.g:
  ## extraHosts:
  ##   - name: overseerr.local
  ##     path: /
  ##
  extraHosts: [] # From v1 hosts structure
  ## @param ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
  ## e.g:
  ## extraPaths:
  ## - path: /*
  ##   backend:
  ##     serviceName: ssl-redirect
  ##     servicePort: use-annotation
  ##
  extraPaths: []
  ## @param ingress.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
  ## e.g:
  ## extraTls:
  ## - hosts:
  ##     - overseerr.local
  ##   secretName: overseerr.local-tls
  ##
  extraTls: [] # From v1 tls structure
  ## @param ingress.secrets Custom TLS certificates as secrets
  ## NOTE: 'key' and 'certificate' are expected in PEM format
  ## NOTE: 'name' should line up with a 'secretName' set further up
  ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
  ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  ## e.g:
  ## secrets:
  ##   - name: overseerr.local-tls
  ##     key: |-
  ##       -----BEGIN RSA PRIVATE KEY-----
  ##       ...
  ##       -----END RSA PRIVATE KEY-----
  ##     certificate: |-
  ##       -----BEGIN CERTIFICATE-----
  ##       ...
  ##       -----END CERTIFICATE-----
  ##
  secrets: [] # From v1 tls structure
  ## @param ingress.extraRules Additional rules to be covered with this ingress record
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
  ## e.g:
  ## extraRules:
  ## - host: example.local
  ##     http:
  ##       path: /
  ##       backend:
  ##         service:
  ##           name: example-svc
  ##           port:
  ##             name: http
  ##
  extraRules: []

## @section Persistence Parameters
##

## Configure persistence settings (adapted from v1 persistence.config)
## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
##
persistence:
  ## @param persistence.enabled Enable persistence using Persistent Volume Claims or other storage types
  ##
  enabled: true # From v1
  ## @param persistence.type Type of persistence to use. Possible values: `pvc`, `nfs`, `iscsi`
  ##
  type: pvc # From v1
  ## @param persistence.mountPath Path to mount the volume at.
  ##
  mountPath: "/config" # From v1
  ## @param persistence.subPath The subdirectory of the volume to mount to, useful in dev environments and one PV for multiple services
  ## Only used when persistence.type is `pvc`
  ##
  subPath: "" # From v1

  ## PVC configuration
  ## Only used when persistence.type is `pvc`
  ##
  pvc:
    ## @param persistence.pvc.storageClass Storage class of backing PVC
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: "" # From v1
    ## @param persistence.pvc.annotations Persistent Volume Claim annotations
    ##
    annotations: {}
    ## @param persistence.pvc.accessModes Persistent Volume Access Modes
    ##
    accessModes:
    - ReadWriteOnce # From v1
    ## @param persistence.pvc.size Size of data volume
    ##
    size: 1Gi # From v1
    ## @param persistence.pvc.existingClaim The name of an existing PVC to use for persistence
    ##
    existingClaim: "" # From v1
    ## @param persistence.pvc.selector Selector to match an existing Persistent Volume for data PVC
    ## If set, the PVC can't have a PV dynamically provisioned for it
    ## E.g.
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param persistence.pvc.dataSource Custom PVC data source
    ##
    dataSource: {}

## @section Init Container Parameters
##

## 'volumePermissions' init container parameters
## Changes the owner and group of the persistent volume mount point to runAsUser:fsGroup values
##   based on the *podSecurityContext/*containerSecurityContext parameters
##
volumePermissions:
  ## @param volumePermissions.enabled Enable init container that changes the owner/group of the PV mount point to `runAsUser:fsGroup`
  ##
  enabled: true # Enabled because non-root user/group is used
  ## OS Shell + Utility image
  ## ref: https://hub.docker.com/r/bitnami/os-shell/tags/
  ## @param volumePermissions.image.registry [default: REGISTRY_NAME] OS Shell + Utility image registry
  ## @param volumePermissions.image.repository [default: REPOSITORY_NAME/os-shell] OS Shell + Utility image repository
  ## @skip volumePermissions.image.tag OS Shell + Utility image tag (immutable tags are recommended)
  ## @param volumePermissions.image.pullPolicy OS Shell + Utility image pull policy
  ## @param volumePermissions.image.pullSecrets OS Shell + Utility image pull secrets
  ##
  image:
    registry: docker.io
    repository: bitnami/os-shell
    tag: 12-debian-12 # Use a fixed version
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## Init container's resource requests and limits
  ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param volumePermissions.resourcesPreset Set init container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if volumePermissions.resources is set (volumePermissions.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano" # Default
  ## @param volumePermissions.resources Set init container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Init container Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param volumePermissions.containerSecurityContext.enabled Enabled init container' Security Context
  ## @param volumePermissions.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in init container
  ## @param volumePermissions.containerSecurityContext.runAsUser Set init container's Security Context runAsUser
  ## NOTE: when runAsUser is set to special value "auto", init container will try to chown the
  ##   data folder to auto-determined user&group, using commands: `id -u`:`id -G | cut -d" " -f2`
  ##   "auto" is especially useful for OpenShift which has scc with dynamic user ids (and 0 is not allowed)
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 0 # Must run as root to chown

## @section Other Parameters
##

## RBAC configuration
##
rbac:
  ## @param rbac.create Specifies whether RBAC resources should be created
  ##
  create: false # Not explicitly enabled in v1
  ## @param rbac.rules Custom RBAC rules to set
  ## e.g:
  ## rules:
  ##   - apiGroups:
  ##       - ""
  ##     resources:
  ##       - pods
  ##     verbs:
  ##       - get
  ##       - list
  ##
  rules: []

## ServiceAccount configuration (adapted from v1)
##
serviceAccount:
  ## @param serviceAccount.create Specifies whether a ServiceAccount should be created
  ##
  create: true # From v1
  ## @param serviceAccount.name The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the common.names.fullname template
  ##
  name: "" # From v1
  ## @param serviceAccount.annotations Additional Service Account annotations (evaluated as a template)
  ##
  annotations: {} # From v1
  ## @param serviceAccount.automountServiceAccountToken Automount service account token for the server service account
  ##
  automountServiceAccountToken: true # Default

## Prometheus metrics
##
metrics:
  ## @param metrics.enabled Enable the export of Prometheus metrics
  ##
  enabled: false # Default
  ## Prometheus Operator ServiceMonitor configuration
  ##
  serviceMonitor:
    ## @param metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (also requires `metrics.enabled` to be `true`)
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.annotations Additional custom annotations for the ServiceMonitor
    ##
    annotations: {}
    ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
    ##
    labels: {}
    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in Prometheus
    ##
    jobLabel: ""
    ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels
    ##
    honorLabels: false
    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped.
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ## e.g:
    ## interval: 10s
    ##
    interval: ""
    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ## e.g:
    ## scrapeTimeout: 10s
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.metricRelabelings Specify additional relabeling of metrics
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.relabelings Specify general relabeling
    ##
    relabelings: []
    ## @param metrics.serviceMonitor.selector Prometheus instance selector labels
    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
    ## selector:
    ##   prometheus: my-prometheus
    ##
    selector: {}
